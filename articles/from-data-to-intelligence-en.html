<!DOCTYPE HTML>
<html>
	<head>
		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-G2VSWFJ4P2"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());

			gtag('config', 'G-G2VSWFJ4P2');
		</script>
		<title>From Data To Intelligence</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<img id="deep-torch-logo" src="../assets/images/logo.jpg" />
						<span id="deep-torch-header" class="logo">Deep Torch</span>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/company/93786086/" class="icon brands fa-linkedin"><span class="label">Linked in</span></a></li>
							<li><a href="https://www.facebook.com/profile.php?id=100091574053236&mibextid=LQQJ4d" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<span class="date">June 2, 2023</span>
									<p style="font-size: 4rem; font-style: normal; font-weight: bolder;">
                                        From Data To Intelligence
                                    </p>
								</header>
								<div >
									<p>
										A lot of you know that Ai models can learn.. but do you actually know how they learn?
Will let us forget about Ai for a little bit and think about the next question: What makes us "as humans" learn? Before answering, you may be wondering why should we know about how humans learn and what the connection between that and how models learn is? Well, as we know, the main inspiration for the concepts of artificial intelligence is the human brain and its mechanism of action, which is why we'll start from here.
									</p>
									<p>
										So back to the last question, when a human want to learn something new (lets say How do children learn to speak) In the beginning, the child does not know at all how to speak, but he will begin to notice how people talk around him, and then with time he will begin to form connections between words and what they mean and how to form sentences. With repetition, the child will be able to understand more connections and form sentences better.
									</p>
									<p>
										And now, if we go back to the main question "how AI models learn?" In a similar way, AI models learn by processing the data and using algorithms to identify patterns and relationships within that data. The process of learning is referred to as "training" the AI model. This process is repeated over and over again until the AI model can accurately predict outcomes based on new data.
									</p>
									<div>
										<p>
											From the above, we can conclude that data is the fuel for AI, so the first step to building the model is data collection, and we can do that in two ways:
										</p>
										<ul>
											<li>Collecting data by ourselves.</li>
											<li>Find and use previously collected data.</li>
										</ul>
									</div>
									<p>
										In the previous two methods, we must pay full attention to the existing data, as errors here may lead to catastrophic results as follows:
suppose you want to train an AI model for facial recognition using a dataset of images of Arabic people. You collect a large dataset of high-quality images of Arabic people and train your model on this data. However, when you test your model on images of African people or any other ethnicities, you find that it performs poorly and has difficulty recognizing faces accurately.
									<br>
									This is an example of bias in AI models due to inadequate or unrepresentative data. If the training data is not diverse enough, the model may not be able to generalize to new data, leading to poor performance and accuracy.
									</p>
									<div>
										<p>
											We conclude that no matter how good the model is, the lack of data or its lack of quality will lead to poor results. In fact, even leading companies in the field of AI have had such problems:
										</p>
										<h3>Amazon's AI recruiting tool</h3>
										<p>
											In 2018, Amazon developed an AI-powered recruiting tool to help identify the best candidates for job openings. However, the tool was found to be biased against women, as it was trained on resumes submitted to the company over a 10-year period, which were primarily from male applicants. As a result, the model learned to penalize resumes that contained terms associated with women, such as "women's" or "female." Amazon ultimately abandoned the tool due to the bias.
										</p>
										<h3>Tesla's Autopilot system</h3>
										<p>
											In 2016, a Tesla Model S crashed into a truck while using the company's Autopilot system, resulting in the death of the driver. The National Transportation Safety Board (NTSB) found that the Autopilot system had failed to recognize the truck due to the bright sunlight, and that the system was not designed to detect the type of hazard presented by the truck. The incident highlighted the importance of collecting diverse and high-quality data for autonomous driving systems.
										</p>
										<h3>IBM Watson's cancer treatment recommendations</h3>
										<p>
											In 2018, a report by Stat News found that IBM Watson's recommendations for cancer treatments were often inaccurate and potentially dangerous. The system was found to make recommendations based on incomplete or outdated data, leading to inappropriate and potentially harmful treatments being recommended to patients.
										</p>
										<h3>Google's language translation system</h3>
										<p>
											In 2018, Google's language translation system was found to exhibit gender bias, as it translated gender-neutral pronouns to gender-specific pronouns based on the gender of the language used. For example, it would translate the Turkish sentence "O bir doktor" (which means "they are a doctor" and does not specify gender) to "He is a doctor" when translated into English. This incident highlighted the potential risks of biased AI models.
										</p>
									</div>
									<p>
										All previous problems were caused by either that the data is not sufficiently diverse or that it contains errors, as well as that the data is correct but has become outdated and unreliable.
									</p>
									<p>
										Finally, we conclude from this that your interest in building a good model is not enough. In the end, this model will learn from the data that you will pass to it, so choose it wisely.
									</p>
								</div>
							</section>

					</div>

				<!-- Footer -->

			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="..assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>