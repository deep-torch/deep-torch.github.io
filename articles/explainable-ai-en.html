<!DOCTYPE HTML>
<html>
	<head>
		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-G2VSWFJ4P2"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());

			gtag('config', 'G-G2VSWFJ4P2');
		</script>
		<title>Explainable AI</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<img id="deep-torch-logo" src="../assets/images/logo.jpg" />
						<span id="deep-torch-header" class="logo">Deep Torch</span>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/company/93786086/" class="icon brands fa-linkedin"><span class="label">Linked in</span></a></li>
							<li><a href="https://www.facebook.com/profile.php?id=100091574053236&mibextid=LQQJ4d" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<span class="date">May 12, 2023</span>
									<p style="font-size: 4rem; font-style: normal; font-weight: bolder;">
                                        Explainable AI
                                    </p>
								</header>
								<div >
									<h2>What is XAI?</h2>
									<p>
										XAI stands for "Explainable Artificial Intelligence". It refers to the development of AI systems that can provide clear explanations of how AI models arrives to their decisions. 
										<br />
										The goal of XAI is to make AI systems more transparent and understandable to humans and to build trust in the decision-making capabilities of these systems. 
									</p>
									<div>
										<h2>What are the most common technique and approaches in XAI? </h2>
										<p>
											Actually, there is more than one technique used in XAI the most common ones are: 
										</p>
										<h3>Interpretable Models</h3>
										<p>
											These are models that are designed to be easily understood by humans. For example, decision trees make decisions based on a series of questions, and rule-based models use simple if-then statements. They provide straightforward explanations for their decisions. 
										</p>
										<h3>Visualization Techniques</h3>
										<p>
											These techniques use visual representations to help humans understand AI decision-making. Feature importance plots show which factors are most influential in predictions, while activation maps highlight areas of focus in images. Visualizations make it easier to see and interpret how AI models work. 
										</p>
										<div class="image main"><img src="../assets/images/vqa.png" alt="heat maps for most important parts" /></div>
										<h3>Post-hoc Explanations</h3>
										<p>
											These explanations come after the AI model has made its predictions. Techniques like LIME create simplified models that explain complex models in a more understandable way. Partial dependence plots show how changing a single factor affects predictions. They provide additional insights into the AI model's behavior. 
										</p>
										<div class="image main"><img src="../assets/images/lime-good.png" alt="lime technique for explaining model predictions" /></div>
										<div class="image main"><img src="../assets/images/lime-bad.png" alt="lime technique explaining bad model predictions" /></div>
										<div class="image main"><img src="../assets/images/interpnet.png" alt="interpnet explaining model predictions" /></div>
										<h3>Interactive Explanations</h3>
										<p>
											These involve interactive tools or interfaces that allow users to explore and interact with AI models. Users can ask questions, tweak input variables, and see how the model responds. This hands-on approach helps users gain a better understanding of the model's decision-making process.
										</p>

									</div>
									<div>
										<h2>XAI Benefits and Applications</h2>
										<p>
											When it comes to XAI benefits we see that XAI helps us with: 
										</p>
										<h3>Improved decision-making</h3>
										<p>
											XAI provides insights into AI models' decision-making processes, allowing humans to understand and trust AI more effectively. This can lead to better collaboration and decision-making. 
										</p>
										<h3>Bias reduction</h3>
										<p>
											By making AI models' inner workings clearer, XAI allows for the detection and correction of biases that might be present, leading to fairer outcomes.
										</p>
										<h3>Model improvement</h3>
										<p>
											Understanding the AI model's rationale can help developers refine the model or identify weaknesses, leading to more accurate and reliable systems.
										</p>
										<h3>User trust</h3>
										<p>
											When users understand how an AI system makes decisions, they are more likely to trust it and adopt it, increasing its overall effectiveness.
										</p>
									</div>
									<div>
										<h2>XAI Limitations and Challenges</h2>
										<p>Although XAI has many great benefits it still has some limitations like: </p>
										
										<h3>Complexity</h3>
										<p>
											Providing explanations for complex AI models, such as deep learning systems, can be challenging due to their inherent complexity and the large number of parameters involved.
										</p>
										<h3>Subjectivity</h3>
										<p>
											Different users may require different levels of explanations or have different preferences for the types of explanations provided. Catering to these diverse needs can be challenging.
										</p>
										<h3>Lack of standardization</h3>
										<p>
											There are no universally accepted standards or metrics for measuring the quality of explanations provided by XAI systems, making it difficult to compare and evaluate different approaches. 
										</p>
									</div>
									<h2>Real-world applications of XAI</h2>
									<p>
										In 2023 we notice that XAI has many real-world applications, itâ€™s part of the healthcare and finance system that enables AI, and it also has a huge impact on autonomous vehicles its crucial in self-driving cars to explain the decisions made by the AI system while navigating, detecting obstacles, and making split-second decisions, Also in image and speech recognition XAI can explain why certain objects or speech patterns are recognized or classified by AI systems and many more fields enables XAI.
									</p>
								</div>
							</section>

					</div>

				<!-- Footer -->

			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="..assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>