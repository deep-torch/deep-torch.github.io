<!DOCTYPE HTML>
<html>
	<head>
		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-G2VSWFJ4P2"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());

			gtag('config', 'G-G2VSWFJ4P2');
		</script>
		<title>ImageBind</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<img id="deep-torch-logo" src="../assets/images/logo.jpg" />
						<span id="deep-torch-header" class="logo">Deep Torch</span>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/company/93786086/" class="icon brands fa-linkedin"><span class="label">Linked in</span></a></li>
							<li><a href="https://www.facebook.com/profile.php?id=100091574053236&mibextid=LQQJ4d" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<span class="date">May 16, 2023</span>
									<p style="font-size: 4rem; font-style: normal; font-weight: bolder;">
                                        ImageBind
                                    </p>
								</header>
								<div dir="rtl">
									<p>
										"IMAGEBIND هي طريقة لتعلم تضمين Embedding مشترك ل 6 أنماط مختلفة للبيانات، و هي الصور، النص، الصوت، العمق، الطاقة الحرارية، و ال IMU (و التي تقيس قوى معينة لجسم ما، التغير في الزاوية، و أحياناً الاتجاه للجسم )."
									</p>
									<p>
										التضمين Embedding هو كفضاء شعاعي نقوم بترميز المعلومات الدلالية ضمن أساسه ( يمكنك التفكير بالأساس على أنه المحاور الخاصة بالفضاء للتبسيط )، على سبيل المثال محور للوجه، و آخر للحيوانات، و آخر لطول الجسم إلخ...
									</p>
									<p>
										انتبه إلى أن المثال السابق مبسط جداً لفهم المغزى. سوف يكون هناك مقال آخر نناقش فيه هذه الفكرة المهمة جداًّ!
									</p>
									<p>
										الفكرة الجوهرية التي يمكن استخلاصها من الورقة أنه "صورة واحدة يمكن أن تريط عدة أحاسيس و تجارب سوية، مثلاً صورة للشاطئ يمكن أن تذكرنا بصوت الأمواج، بقوام الرمل، بالنسيم، أو حتى يمكن أن تكون مصدر الإلهام لقصيدة. خاصية 'الربط' هذه في الصور تقدم مصادر عديدة لتوجيه تعلم الميزات features المرئية، عن طريق ربطها بأي من الأحاسيس أو التجارب المرتبطة بالصور.
									</p>
									<p>
										"لسنا بحاجة إلى مجموعة بيانات dataset بحيث كل الأنماط المختلفة للبيانات تتواجد سوية من أجل كل عنصر. بدلاً من ذلك، سنستفيد من خاصية الربط للصور، و نظهر أن ربط تضمين أي نمط بيانات بتضمين الصور فقط يؤدي إلى ربط على مستوى كل الأنماط."
									</p>
									<p>
										المقصود هنا أنه بشكل عام، لتدريب نموذج ليكون جيداً في أنماط مختلفة من البيانات سوية، يجب علينا استخدام كل الأنماط في كل عنصر تدريب.
									</p>
									<p>
										على سبيل المثال، إذا كنا نريد أن نربط صوت أمواج البحر مع النص "أمواج البحر" مع صورة للأمواج، علينا تقديم ما يلي للنموذج كعنصر واحد:
										<br />
										( صورة أمواج البحر، صوت أمواج البحر، النص "أمواج البحر")
										<br />
										هذا صعب جداً، خاصة عندما يكون لدينا العديد من أنماط البيانات، و لكن الطريقة الخاصة بهذه الورقة تحتاج فقط إلى وجود الصور مع كل نمط آخر، أي من أجل مثالنا السابق يصبح لدينا عنصرين كما يلي:
										<br />
										( صورة أمواج البحر، صوت أمواج البحر)، (صورة أمواج البحر، النص "أمواج البحر").
									</p>
									<p>
										هذا مختلف عن الطرق السابقة كما ذكر في الورقة:
										<br />
										"في المقابل، IMAGEBIND لا تحتاج إلى بيانات مرتبطة بشكل مباشر بين كل الأنماط، بدلاً من ذلك نستعمل الصورة كتوجيه طبيعي ضعيف weak supervision لتوحيد كل الأنماط."
									</p>
									<p>
										المقصود هنا بالتوجيه الضعيف أننا لا نقوم بإعطاء النموذج الربط بين كل الأنماط. بدلاً من ذلك نعتمد على خاصية الربط الطبيعي في الصور.
									</p>
									<p>
										<b>لكن كيف تم تدريب هذا النموذج؟</b>
										<br />
										أولاً، تم استعمال معمارية Transformer لترميز البيانات إلى أشعة ( مرمز من أجل كل نمط، ما عدا الصور و الفيديو تم استعمال مرمز واحد لهما سوية) بحيث يمكن تعلم التضمينات.
									</p>
									<p>
										تم استعمال Contrastive learning، و الذي هوي عبارة عن طريقة عامة لتعلم فضاء التضمينات عن طريق استعمال أزواج من الأمثلة المتقاربة ( موجبة ) و أمثلة غير متقاربة ( سالبة ).
									</p>
									<p>
										لندعو تضمين الصور ب q_i و تضمين النمط الآخر من البيانات k_i.
تابع الخطأ يدفع النموذج لجعل q_i و k_i أقرب في فضاء التضمينات المشترك، و بهذا يربط الصورة مع النمط الآخر.
									</p>
									<p>
										هذا تقدم كبير، ﻷن هذا النموذج سوف يتعلم مفاهيم أفضل عن العالم و سوف يمتلك فهم عام جيد.
هذه النماذج تدعى النماذج التأسيسية ﻷنه يمكن استعمالهم لبناء النماذج للمهام الأخرى و ذلك بسبب الفهم العام الذي تمتلكه هذه النماذج. هذه النماذج تشبه نماذج مثل BERT و GPT في مجال معالجة اللغات الطبيعية NLP على سبيل المثال.
									</p>
									<a href="https://arxiv.org/abs/2305.05665">الورقة</a>
								</div>
							
							</section>

					</div>

				<!-- Footer -->

			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="..assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>