<!DOCTYPE HTML>
<html>
	<head>
		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-G2VSWFJ4P2"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());

			gtag('config', 'G-G2VSWFJ4P2');
		</script>
		<title>Explainable AI</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<img id="deep-torch-logo" src="../assets/images/logo.jpg" />
						<span id="deep-torch-header" class="logo">Deep Torch</span>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/company/93786086/" class="icon brands fa-linkedin"><span class="label">Linked in</span></a></li>
							<li><a href="https://www.facebook.com/profile.php?id=100091574053236&mibextid=LQQJ4d" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<span class="date">May 12, 2023</span>
									<p style="font-size: 4rem; font-style: normal; font-weight: bolder;">
                                        الذكاء الاصطناعي القابل للتفسير
                                    </p>
								</header>
								<div dir="rtl">
									<h2>ما هو ال XAI ؟ </h2>
									<p>
										XAI ترمز الى  الذكاء الاصطناعي القابل للتفسير “Explainable Artificial Intelligence" و  تشير إلى تطوير أنظمة الذكاء الاصطناعي التي يمكنها تقديم تفسيرات واضحة حول كيفية وصولها لقراراتها. 
										<br />
										هدف XAI هو جعل أنظمة الذكاء الاصطناعي أكثر شفافية وفهمًا للبشر، وبناء الثقة في قدرات صنع القرار لهذه الأنظمة الذكية. 
									</p>
									<div>
										<h2>ماهي اكثر التقنيات المستعملة في الXAI ؟ </h2>
										<p>
											هنالك العديد من التقنيات المستعملة في هذا المجال و أبرزها: 
										</p>
										<h3>النماذج القابلة للتفسير (Interpretable Models)</h3>
										<p>
											هذه هي النماذج (models)  التي تم تصميمها ليتم فهمها بسهولة من قبل البشر. على سبيل المثال، تقوم أشجار القرار باتخاذ القرارات استنادًا إلى سلسلة من الأسئلة، وتستخدم النماذج المبنية على القواعد تصريحات بسيطة (if – else).حيث تقدم هذه النماذج تفسيرات مباشرة لقراراتها. 
										</p>
										<h3>تقنيات التمثيل المرئي (Visualization Techniques) </h3>
										<p>
											تستخدم هذه التقنيات التمثيلات البصرية لمساعدة البشر في فهم عملية اتخاذ القرار من قبل الذكاء الاصطناعي، حيث انها تشمل رسوم توضح بها العوامل الاكثر اهمية تبعاًُ لتأثيرها على نتيجة النموذج، بينما تسلط خرائط التنشيط (activation maps) الضوء على مناطق التركيز في الصور، أي ما الذي يركز النموذج عليه. 
											تسهل هذه التمثيلات فهم كيفية عمل نماذج الذكاء الاصطناعي. 
										</p>
										<div class="image main"><img src="../assets/images/vqa.png" alt="heat maps for most important parts" /></div>
										<h3>تفسيرات ما بعد القرار (Post-hoc Explanations) </h3>
										<p>
											هذه التفسيرات تأتي بعد أن تقوم نماذج الذكاء الاصطناعي بتوقعاتها. 
											<br />
											تقنيات مثل LIME تقوم بإنشاء نماذج مبسطة تشرح النماذج المعقدة بطريقة أكثر فهمًا. توضح الرسومات الجزئية للتبعية كيف يؤثر تغيير عامل واحد على التوقعات بحيث توفر هذه التفسيرات رؤى إضافية حول سلوك نموذج الذكاء الاصطناعي. 
										</p>
										<div class="image main"><img src="../assets/images/lime-good.png" alt="lime technique for explaining model predictions" /></div>
										<div class="image main"><img src="../assets/images/lime-bad.png" alt="lime technique explaining bad model predictions" /></div>
										<div class="image main"><img src="../assets/images/interpnet.png" alt="interpnet explaining model predictions" /></div>
										<h3>التفسيرات التفاعلية (Interactive Explanations) </h3>
										<p>
											تشمل هذه التفسيرات أدوات أو واجهات تفاعلية تسمح للمستخدمين باستكشاف والتفاعل مع نماذج الذكاء الاصطناعي. يمكن للمستخدمين طرح الأسئلة، وتعديل المتغيرات المدخلة، ومشاهدة كيف يتفاعل النموذج. يساعد هذه النهج العملي المستخدمين على فهم عملية اتخاذ القرارات بشكل أفضل. 
										</p>

									</div>
									<div>
										<h2>فوائد وتطبيقات  ال XAI </h2>
										<p>
											نتج من هذا المجال العديد من التطبيقات والفوائد لعل أبرزها: 
										</p>
										<h3>تحسين عملية اتخاذ القرار </h3>
										<p>
											يوفر XAI نظرة داخل عملية اتخاذ القرار لنماذج الذكاء الاصطناعي، مما يتيح للبشر فهم هذه النماذج و الوثوق بها بشكل أكثر فعالية. يمكن أن يؤدي ذلك إلى تحسين التعاون واتخاذ القرارات. 
										</p>
										<h3>تحسين النموذج </h3>
										<p>
											يمكن أن يساعد فهم كيف تقوم هذه النماذج باتخاذ القرار المطورين على تحسين النموذج أو تحديد نقاط الضعف، مما يؤدي إلى إنشاء أنظمة أكثر دقة وموثوقية. 
										</p>
										<h3>تقليل التحيز (bias reduction) </h3>
										<p>
											عن طريق جعل طريقة عمل النماذج واضحة، يمكن كشف و تصحيح التحيز في حال وجوده مما يؤدي إلى نماذج خالية من التحيز. 
										</p>
										<h3>ثقة المستخدم</h3>
										<p>
											عندما يفهم المستخدمون كيفية اتخاذ نظام الذكاء الاصطناعي للقرارات، فإنهم أكثر استعدادًا للثقة به واعتماده، مما يزيد من فعاليته العامة. 
										</p>
									</div>
									<div>
										<h2>التحديات والعقبات التي تواجه XAI </h2>
										<p>على الرغم من أنه يحمل العديد من الفوائد الكبيرة، إلا أن يواجه بعض القيود والتحديات مثل: </p>
										
										<h3>التعقيد</h3>
										<p>
											توفير تفسيرات لنماذج الذكاء الاصطناعي المعقدة، مثل أنظمة التعلم العميق (deep learning)، يمكن أن يكون تحديًا بسبب التعقيد الكبير لهذه النماذج والعدد الكبير من العوامل المشاركة في اتخاذ القرار. 
										</p>
										<h3>الموضوعية</h3>
										<p>
											قد يحتاج المستخدمون المختلفون إلى مستويات مختلفة من التفسيرات أو قد يكون لديهم تفضيلات مختلفة فيما يتعلق بنوعية التفسيرات المقدمة. تلبية هذه الاحتياجات المتنوعة يمكن أن يكون تحديًا. 
										</p>
										<h3>غياب المعايير</h3>
										<p>
											لا توجد معايير أو مقاييس مقبولة عالمياً لقياس جودة التفسيرات التي توفرها أنظمة XAI ، مما يجعل من الصعب مقارنة وتقييم النهج المختلفة. 
										</p>
									</div>
									<h2>تطبيقات XAI في العالم </h2>
									<p>
										في عام 2023، نلاحظ أن XAI له العديد من التطبيقات في العالم. فهو جزء من انظمة الرعاية الصحية والنظام المالي التي تستخدم تقنيات الذكاء الاصطناعي، وله أيضًا تأثير كبير على القيادة الذاتية في السيارات، حيث ان له دور كبير في شرح القرارات التي يتخذها نظام الذكاء الاصطناعي أثناء التنقل واكتشاف العوائق واتخاذ القرارات في جزء من الثانية. بالإضافة إلى ذلك، في مجالات التعرف على الصور والكلام،  XAI  قادر على أن يشرح لماذا يتم التعرف على كائنات معينة أو أنماط الكلام المعترف بها أو تصنيفها من قبل نظم الذكاء الاصطناعي وغيرها من المجالات التي يتاح فيها استخدام ال XAI.
									</p>
								</div>
							
							</section>

					</div>

				<!-- Footer -->

			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="..assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>